# -*- coding: utf-8 -*-
"""Diffusion2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B65MNtQGRI8LjdAmSHZcWZ9NcfrW-n-W
"""

#



# Cell 1: Train a denoising model to reverse 10 steps of noise added to 5 fixed sine curves
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# --- Config ---
n_points = 100
n_steps = 10
batch_size = 1
noise_std = 0.4

# --- Generate 5 shifted sine curves ---
def generate_shifted_sine_batch(n_shifts=5, n_points=100):
    phases = torch.linspace(0, 2 * torch.pi, n_shifts)
    x = torch.linspace(0, 2 * torch.pi, n_points)
    sines = torch.stack([torch.sin(x + shift) for shift in phases])  # [5, n_points]
    return x, sines

# --- Denoising model ---
class DenoiseMLP(nn.Module):
    def __init__(self, n_points):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(n_points, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 8),
            nn.ReLU(),
            nn.Linear(8, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, n_points)
        )

    def forward(self, x):
        return self.net(x)

# --- Noise step function ---
def add_noise_step(x, noise_level):
    return x + noise_level * torch.randn_like(x)

# --- Training loop ---
x_grid, sine_set = generate_shifted_sine_batch(n_shifts=5, n_points=n_points)
model = DenoiseMLP(n_points)
optimizer = optim.Adam(model.parameters(), lr=0.0001)
loss_fn = nn.MSELoss()

for epoch in range(2000):
    idx = torch.randint(0, sine_set.size(0), (batch_size,))
    x_clean = sine_set[idx]  # [B, n_points]

    # Generate noisy trajectory
    x_t = x_clean.clone()
    trajectory = [x_t.clone()]
    for _ in range(n_steps):
        x_t = add_noise_step(x_t, noise_std / n_steps)
        trajectory.append(x_t.clone())

    # Reverse denoising step-by-step
    loss = 0.0
    for step in reversed(range(1, n_steps + 1)):
        x_input = trajectory[step]
        x_target = trajectory[step - 1]
        x_pred = model(x_input)
        loss += loss_fn(x_pred, x_target)

    loss /= n_steps
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if epoch % 200 == 0:
        print(f"Epoch {epoch}: Loss = {loss.item():.6f}")

# Cell 2: Sample from noise, show denoising steps and compare to training sines
import torch
import matplotlib.pyplot as plt

@torch.no_grad()
def sample_from_noise(model, n_steps=10, n_points=100, noise_std=0.4):
    x = noise_std * torch.randn(1, n_points)
    steps = [x.squeeze().clone()]
    for _ in range(n_steps):
        x = model(x)
        steps.append(x.squeeze().clone())
    return steps

# Sample denoising trajectory
steps = sample_from_noise(model, n_steps=n_steps, n_points=n_points, noise_std=noise_std)

# Plot denoising steps
plt.figure(figsize=(12, 6))
for i, x_i in enumerate(steps):
    plt.plot(x_grid, x_i, label=f"Step {i}", alpha=0.7)
plt.title("Denoising Trajectory from Pure Noise")
plt.legend()
plt.grid(True)
plt.show()

# Final result
final = steps[-1]

# Compare to training sines
distances = torch.stack([torch.mean((final - s)**2) for s in sine_set])
closest = torch.argmin(distances).item()
print(f"Final output is closest to training sine #{closest+1} | MSE = {distances[closest]:.6f}")

# Plot final sample vs training sine functions
plt.figure(figsize=(10, 5))
plt.plot(x_grid, final, label='Final Sample (Step 10)', linewidth=2, linestyle='--', color='black')
for i in range(sine_set.size(0)):
    plt.plot(x_grid, sine_set[i], label=f'Training Sine {i+1}', alpha=0.6)
plt.title("Final Output Compared to Training Sine Curves")
plt.legend()
plt.grid(True)
plt.show()