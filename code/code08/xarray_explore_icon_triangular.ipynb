{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyresample\n",
    "# ! pip install xarray[complete]\n",
    "# ! pip install uxarray # only needed for last chapter of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as mtri\n",
    "import xarray\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import subprocess\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import pyresample.geometry as pgeom\n",
    "import pyresample.utils as putils\n",
    "import pyresample.kd_tree as pkdt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = dt.datetime.now().strftime('%Y%m%d00') # string for today 00utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's download some T2M grib data LT=12hrs, init: today 0UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mfile = f\"icon_global_icosahedral_single-level_{date}_012_T_2M.grib2.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget \"http://opendata.dwd.de/weather/nwp/icon/grib/00/t_2m/{t2mfile}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!bzip2 -d \"{t2mfile}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://icon-downloads.mpimet.mpg.de/grids/public/edzw/icon_grid_0026_R03B07_G.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cfgrib backend of xarray: easy to use, but can be slooooooow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xarray.open_dataarray(f'./icon_global_icosahedral_single-level_{date}_012_T_2M.grib2',engine='cfgrib', decode_timedelta=False)\n",
    "ds = ds.rename(values='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = xarray.open_dataset('./icon_grid_0026_R03B07_G.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = xarray.Dataset(dict(T2M=ds), coords=dict(latitude=grid.clat, longitude=grid.clon))\n",
    "full['longitude']  = np.rad2deg(full[\"clon\"])\n",
    "full['latitude']  = np.rad2deg(full[\"clat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simplest way to plot triangular data without fancy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from the ICON trainings course\n",
    "crs = ccrs.PlateCarree()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={\"projection\":crs})\n",
    "\n",
    "def axis_settings(ax, title):\n",
    "    gl = ax.gridlines(crs=crs, draw_labels=True,\n",
    "                      linewidth=.6, color='gray')\n",
    "    ax.add_feature(cf.COASTLINE.with_scale(\"50m\"), lw=0.5)\n",
    "    ax.add_feature(cf.BORDERS.with_scale(\"50m\"), lw=0.3)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "axis_settings(ax, \"T2M\")\n",
    "filled_c0 = ax.tricontourf(full.longitude, full.latitude, full[\"T2M\"][:], transform=crs)\n",
    "fig.colorbar(filled_c0, orientation='horizontal', ax=ax);\n",
    "ax.set_extent([5,10,55,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more sophisticated: plot triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tri(grid):\n",
    "    \"\"\"\n",
    "    grid: xarray.Dataset from gridfile\n",
    "    \"\"\"\n",
    "    # ! 1 based indexing in grid file\n",
    "    return mtri.Triangulation(180./np.pi*grid['vlon'],180./np.pi*grid['vlat'],(grid['vertex_of_cell']-1).T)\n",
    "\n",
    "def plot_tri(da,grid, ax=None, **kwargs):\n",
    "    # expect da=xarray.DataArray with grid file coords in da.coords\n",
    "    # kwargs go to tripcolor\n",
    "\n",
    "    triangulation = create_tri(grid)\n",
    "    triangulation, values = fix_dateline_triangles(triangulation, da.values, False)\n",
    "    subplotkw = dict(projection=ccrs.PlateCarree())\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(1, subplot_kw=subplotkw)\n",
    "    cax = ax.tripcolor(triangulation, values, **kwargs)\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(draw_labels=True)\n",
    "    return ax,triangulation,cax\n",
    "    \n",
    "def fix_dateline_triangles(triangulation, values, mask_only=False): # gernot\n",
    "    \"\"\"Fix triangles crossing the date line.\n",
    "\n",
    "    Triangles crossing the horizontal map boundary are plotted across\n",
    "    the whole two-dimensional plane of the PlateCarree projection\n",
    "    (eg. from -180 degrees to 180 degrees), while they should \"wrap\n",
    "    around the back\". For the respective triangles on either side of\n",
    "    the plot, the vertices beyond the date line - on thus on the\n",
    "    opposite side of the plot - are re-set to a value on the same side\n",
    "    and the triangle is duplicated on the other side.\n",
    "\n",
    "    To visualize this effect, use mask_only=True. In this case, the\n",
    "    triangles are not duplicated and the respective triangles are only\n",
    "    masked and will not be plotted.\n",
    "    \n",
    "    (ideas taken from the ICON Model Tutorial 2019, section 9.3.3)\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    triangulation : Triangulation\n",
    "        the triangulation to be fixed\n",
    "    values : ndarray\n",
    "        the values corresponding to the triangulation\n",
    "    mask_only : bool, optional\n",
    "        whether to mask the triangles without changing the vertices\n",
    "            \n",
    "    Returns     \n",
    "    -------                                       \n",
    "    triangulation_fixed : Triangulation \n",
    "        the triangulation with modified triangles and vertices\n",
    "    values_fixed : ndarray\n",
    "        the values with duplicated values for duplicated triangles appended\n",
    "\n",
    "    \"\"\"\n",
    "    to_fix = np.argwhere(triangulation.x[triangulation.triangles].max(axis=1) \n",
    "                                               - triangulation.x[triangulation.triangles].min(axis=1) > 200)[:, 0]\n",
    "\n",
    "    # create a new Triangulation object to avoid overwriting the original data\n",
    "    triangulation_fixed = mtri.Triangulation(triangulation.x, triangulation.y, triangulation.triangles)\n",
    "\n",
    "    if mask_only:\n",
    "        triangulation_fixed.mask = np.full(triangulation.triangles.shape[0], False)\n",
    "        triangulation_fixed.mask[to_fix] = True\n",
    "    else:\n",
    "        values_fixed = values.copy()\n",
    "        k = triangulation.x.shape[0]\n",
    "        for i in to_fix:\n",
    "            # append the mirrored triangle and its value to the existing triangles and values\n",
    "            triangle = triangulation.triangles[i]\n",
    "            triangulation_fixed.triangles = np.vstack([triangulation_fixed.triangles, triangle])\n",
    "            values_fixed = np.append(values_fixed, values[i])\n",
    "\n",
    "            # adjust the vertices of the appended triangle such that all lon values are > 0\n",
    "            idx_vertex = np.argwhere(triangulation.x[triangle]<0)\n",
    "            for j in idx_vertex:\n",
    "                triangulation_fixed.x = np.append(triangulation_fixed.x,\n",
    "                                                  triangulation.x[triangle[j]] + 360)\n",
    "                triangulation_fixed.y = np.append(triangulation_fixed.y,\n",
    "                                                  triangulation.y[triangle[j]])\n",
    "                triangulation_fixed.triangles[-1, j] = k\n",
    "                k = k+1\n",
    "\n",
    "            # adjust the vertices of the original, copied triangle such that all lon values are < 0\n",
    "            idx_vertex = np.argwhere(triangulation.x[triangle]>0)\n",
    "            for j in idx_vertex:\n",
    "                triangulation_fixed.x = np.append(triangulation_fixed.x,\n",
    "                                                  triangulation.x[triangle[j]] - 360)\n",
    "                triangulation_fixed.y = np.append(triangulation_fixed.y,\n",
    "                                                  triangulation.y[triangle[j]])\n",
    "                triangulation_fixed.triangles[i, j] = k\n",
    "                k = k+1\n",
    "\n",
    "    return triangulation_fixed, values_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tri, cax = plot_tri(full['T2M'], grid,vmin=270,vmax=290);\n",
    "ax.set_extent([5,10,55,60])\n",
    "plt.colorbar(cax,label='T2M', shrink=0.6)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remap to custom points: here just one meridian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(*args):\n",
    "    \"\"\"Return a generator for the Cartesian product of args\n",
    "    (https://confluence.ecmwf.int/display/ECC/grib_index, Python tab).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args : sequence of sequences\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    generator\n",
    "        yielding tuples from the Cartesian product of args\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = [[]]\n",
    "    for pool in args:\n",
    "        result = [x + [y] for x in result for y in pool]\n",
    "    for i in result:\n",
    "        yield tuple(i)\n",
    "\n",
    "\n",
    "method='gauss'; sigma=20; cutoff=None\n",
    "\n",
    "def compute_xsection(da, lllat, lllon, method='gauss', sigma=20, cutoff=None, lev=None):\n",
    "        \"\"\"\n",
    "        Interpolation to pairs of lllat,lllon values (uses pyresample!)\n",
    "        \n",
    "        da :            xarray.DataArray, to be interpolated. \n",
    "                         Required coords: longitude, latitude (deg), cells\n",
    "        lllat,lllon :   xarray.DataArray, 1D target coordinates (deg)\n",
    "        method :         str, options: 'gauss', 'nearest'\n",
    "        sigma, cutoff : only for method='gauss'\n",
    "        lev :           xarray.DataArray (1d), optional. \n",
    "                        expected to be called 'height', in target array, can be renamed otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        if lev is not None:\n",
    "            target = xarray.zeros_like(lev+lllat) # hack to get z dimension!\n",
    "        else:\n",
    "            target = xarray.zeros_like(lllat)\n",
    "        target.name = da.name\n",
    "\n",
    "\n",
    "        source_geo = pgeom.SwathDefinition(\n",
    "                        *putils.check_and_wrap(da.coords['longitude'].values,\n",
    "                                               da.coords['latitude'].values\n",
    "                                               )\n",
    "                                           )\n",
    "\n",
    "        target_geo = pgeom.SwathDefinition(\n",
    "                        *putils.check_and_wrap(target.coords['longitude'].values,\n",
    "                                               target.coords['latitude'].values\n",
    "                                               )\n",
    "                                           )\n",
    "\n",
    "        if method == 'gauss':\n",
    "            sigma = sigma * 1000\n",
    "            if cutoff is None:\n",
    "                cutoff = 5 * sigma\n",
    "            resample_args = [cutoff, sigma]\n",
    "            resample_func = getattr(pkdt, 'resample_gauss')\n",
    "\n",
    "        elif method == 'nearest':\n",
    "            if cutoff is None:\n",
    "                cutoff = 50000\n",
    "            resample_args = [cutoff]\n",
    "            resample_func = getattr(pkdt, 'resample_nearest')\n",
    "\n",
    "        # derive dimensions and their sizes of the result\n",
    "        # 1) take da.sizes and remove lat and lon dims\n",
    "        # 2) use this intermediate result to set up the prod generator used below\n",
    "        # 3) add the lat and lon dims and sizes of target\n",
    "        result_sizes = OrderedDict(da.sizes)\n",
    "        for c in ['latitude', 'longitude']:\n",
    "            _ = [result_sizes.pop(d, None) for d in da[c].dims]\n",
    "\n",
    "        prod = list(product(*[range(d) for d in result_sizes.values()]))\n",
    "        #print(result_sizes, prod)\n",
    "        non_horiz_dims = result_sizes.keys()\n",
    "\n",
    "        result_sizes.update(target['cells'].sizes)\n",
    "\n",
    "        # loop over horizontal slices to avoid creation of temporary data array\n",
    "        # with swapped axes for pkdt.resample_xyz\n",
    "        result = np.ones(tuple(result_sizes.values()))\n",
    "        for sel in prod:\n",
    "            sel_dict = {dim: i for dim, i in zip(non_horiz_dims, sel)}\n",
    "            print(f'Interpolate {sel_dict}')\n",
    "            result[sel] = resample_func(source_geo, da[sel_dict].values, target_geo, *resample_args)\n",
    "        \n",
    "        coords = {'latitude': ('cells',target.coords['latitude'].values),\n",
    "                  'longitude':('cells',target.coords['longitude'].values),\n",
    "                  'cells':('cells',target.coords['cells'].values)\n",
    "                  }\n",
    "        if lev is not None:\n",
    "            coords['height'] = lev\n",
    "\n",
    "        target.values = result\n",
    "        target = target.assign_coords(coords)\n",
    "        return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lllat = xarray.DataArray(np.arange(-90,90, 2, dtype=np.float64), name='latitude',dims='cells')\n",
    "lllon = xarray.zeros_like(lllat) + 10.\n",
    "lllon.name = 'longitude'\n",
    "lllat=lllat.assign_coords(dict(latitude=lllat, longitude=lllon))\n",
    "lllon=lllon.assign_coords(dict(latitude=lllat, longitude=lllon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = compute_xsection(full['T2M'],lllat,lllon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.plot(x='latitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vertical crossection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download some icond2: use today 00UTC init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://icon-downloads.mpimet.mpg.de/grids/public/edzw/icon_grid_0047_R19B07_L.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ifileP = 'icon-d2_germany_icosahedral_model-level_{date}_000_{lev}_qv.grib2.bz2'\n",
    "#\n",
    "#for lev in np.arange(65,45,-1):\n",
    "#    subprocess.check_call(['wget', \n",
    "#     'http://opendata.dwd.de/weather/nwp/icon-d2/grib/00/qv/'+ ifileP.format(lev=lev,date=date)])\n",
    "#    subprocess.check_call(['bzip2','-d',ifileP.format(lev=lev,date=date)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ifileP = 'icon-d2_germany_icosahedral_time-invariant_{date}_000_{lev}_hhl.grib2.bz2'\n",
    "\n",
    "# for lev in np.arange(65,45,-1):\n",
    "#     subprocess.check_call(['wget', \n",
    "#      'http://opendata.dwd.de/weather/nwp/icon-d2/grib/00/hhl/'+ ifileP.format(lev=lev,date=date)])\n",
    "#     subprocess.check_call(['bzip2','-d',ifileP.format(lev=lev,date=date)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and quickview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridfID2 = 'icon_grid_0047_R19B07_L.nc'\n",
    "gridD2 = xarray.open_dataset(gridfID2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = xarray.open_mfdataset(f'icon-d2_germany_icosahedral_model-level_{date}_000_??_qv.grib2', engine='cfgrib',\n",
    "                          concat_dim='generalVerticalLayer', combine='nested', decode_timedelta=False)\n",
    "qv = qv.rename(values='cell') # is called values...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignoring that hhl is actually half levels here\n",
    "hhl = xarray.open_mfdataset(f'./icon-d2_germany_icosahedral_time-invariant_{date}_000_??_hhl.grib2', engine='cfgrib',\n",
    "                          concat_dim='generalVerticalLayer', combine='nested', decode_timedelta=False)\n",
    "hhl = hhl.rename(values='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = qv.assign_coords(hhl=hhl['HHL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullID2 = xarray.Dataset(dict(QV=qv['QV']), coords=dict(latitude=np.rad2deg(gridD2.clat), longitude=np.rad2deg(gridD2.clon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullID2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tri, cax = plot_tri(qv['QV'].sel(generalVerticalLayer=65), gridD2,vmin=qv.QV.min().values, vmax=qv.QV.max().values);\n",
    "#ax.set_extent([5,10,55,60])\n",
    "plt.colorbar(cax, shrink=0.6, label=qv.QV.long_name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crossection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do vertical interpolation first (1d problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target vertical heights to which we wish to interpolate\n",
    "z = xarray.DataArray([20,100,250,500,750, 1000.], name='Z', dims=['Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize(signature='(m),(m),(p)->(p)',excluded={'xout'})\n",
    "def interp1d(xin, yin, xout):\n",
    "    return np.interp(xout, xin, yin,left=np.nan) # left: do not extrapolate below lowest model level\n",
    "\n",
    "interpolat_array = interp1d(qv.hhl.values[::-1,:].T, fullID2.QV.values[::-1,:].T,z.values)\n",
    "interpolatV = xarray.DataArray(interpolat_array, dims=('cell','Z'))\n",
    "interpolatV = interpolatV.assign_coords(latitude=fullID2['latitude']) # automatically copies longitude as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolatV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check interpolation for a random column\n",
    "plt.plot(qv.QV.values[::-1,50000],qv.hhl.values[::-1,50000], label='original profile')\n",
    "plt.scatter(np.interp(z,qv.hhl.values[::-1,50000], qv.QV.values[::-1,50000]),z, label='single col interpolation') \n",
    "plt.scatter(interpolatV.isel(cell=50000),z, marker='x', label='batch computed interpolation')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do horizontal interpolation: example from Hamburg to Munich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose transsect HH Munich\n",
    "ham = [55, 10]\n",
    "muc = [48, 12]\n",
    "\n",
    "lllat = xarray.DataArray(np.linspace(ham[0], muc[0], 100, dtype=np.float64), name='latitude',dims='cells')\n",
    "lllon = xarray.DataArray(np.linspace(ham[1], muc[1], 100, dtype=np.float64), name='longitude',dims='cells')\n",
    "lllat=lllat.assign_coords(dict(latitude=lllat, longitude=lllon))\n",
    "lllon=lllon.assign_coords(dict(latitude=lllat, longitude=lllon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = compute_xsection(interpolatV, lllat, lllon, method='gauss', sigma=20, cutoff=None, lev=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.plot.contourf(x='latitude',y='height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for fun: interpolate horizontally without vertical interpolation to common height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = compute_xsection(fullID2['QV'], lllat, lllon, method='nearest', sigma=20, cutoff=None, lev=fullID2.generalVerticalLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2.plot.contourf(x='latitude', y='generalVerticalLayer', yincrease=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uxarray: xarray for unstructured grids (Update!)\n",
    "\n",
    "`uxarray` is a package under heavy developement. This means functionalities may change quickly or stop working. \n",
    "\n",
    "In April 2025, the simple plotting of global data on triangular grid was even easier than the xarray solution presented above. \n",
    "\n",
    "**WARNING**: it may not be trivial to install uxarray on DWD's rcl in the python 3.10 setup! It was easy to install it in an environment on SuSe 15.6 using python 3.12. Plots on triangular grids were not produced within a reasonable time and creating regional subsets ended with a core dump. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uxarray as ux\n",
    "import hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ux.open_dataset('./icon_grid_0026_R03B07_G.nc',\n",
    "                       f'./icon_global_icosahedral_single-level_{date}_012_T_2M.grib2',\n",
    "                       engine='cfgrib', decode_timedelta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot.extension('matplotlib') # default backend is hvplot/bokeh\n",
    "ds.t2m.plot(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is interactive by default\n",
    "hvplot.extension('bokeh')\n",
    "ds.t2m.plot.polygons(cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp3.12",
   "language": "python",
   "name": "dp3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
