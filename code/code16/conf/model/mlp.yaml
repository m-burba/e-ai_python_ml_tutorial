
layer_sizes: [1, 128, 1]
activation: relu
